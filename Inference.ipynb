{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16446,"status":"ok","timestamp":1699556508859,"user":{"displayName":"Adriel dos Santos Araujo Cabral","userId":"01219458395452816246"},"user_tz":180},"id":"S0eGbTaHJwHJ","outputId":"32c3ee2f-acbd-4ba9-a4ff-0751d1f0a2b3"},"outputs":[],"source":["!pip install --no-cache-dir transformers sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T12:19:37.846866Z","iopub.status.busy":"2023-11-04T12:19:37.846447Z","iopub.status.idle":"2023-11-04T12:19:52.307192Z","shell.execute_reply":"2023-11-04T12:19:52.305975Z","shell.execute_reply.started":"2023-11-04T12:19:37.846830Z"},"id":"f53351de","papermill":{"duration":9.64213,"end_time":"2022-10-18T01:53:17.259565","exception":false,"start_time":"2022-10-18T01:53:07.617435","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import random\n","import math\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import AdamW\n","from torch import autocast\n","\n","import transformers\n","from transformers import TrainingArguments, Trainer\n","from transformers import AutoTokenizer, AutoConfig, AutoModel\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20947,"status":"ok","timestamp":1699556539242,"user":{"displayName":"Adriel dos Santos Araujo Cabral","userId":"01219458395452816246"},"user_tz":180},"id":"doinHjIBJp7c","outputId":"4c2f4650-3ca6-495a-ce79-ddcbf04d5648"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-11-04T12:19:52.311581Z","iopub.status.busy":"2023-11-04T12:19:52.310467Z","iopub.status.idle":"2023-11-04T12:19:52.326945Z","shell.execute_reply":"2023-11-04T12:19:52.326083Z","shell.execute_reply.started":"2023-11-04T12:19:52.311538Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699556585425,"user":{"displayName":"Adriel dos Santos Araujo Cabral","userId":"01219458395452816246"},"user_tz":180},"id":"ogZ8R7bUPaKX","outputId":"d18ca692-491f-4e93-e413-4da2066574b8","trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x7e6c07dc0590>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["def seed_everything(seed: int):\n","\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything(0)\n","\n","g = torch.Generator()\n","g.manual_seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T10:17:45.447834Z","iopub.status.busy":"2023-08-29T10:17:45.447289Z","iopub.status.idle":"2023-08-29T10:17:45.459399Z","shell.execute_reply":"2023-08-29T10:17:45.458521Z","shell.execute_reply.started":"2023-08-29T10:17:45.447802Z"},"id":"DPJMS_myPaKZ","trusted":true},"outputs":[],"source":["class MeanHead(nn.Module):\n","    def __init__(self, hidden_size: int, num_hidden_layers: int):\n","        super(MeanHead, self).__init__()\n","\n","        self.linear_output = nn.Sequential(\n","                                nn.Dropout(p = 0.2),\n","                                nn.Linear(hidden_size, 3)\n","                              )\n","\n","    def forward(self, head_inputs: dict):\n","\n","        features = self.get_features(head_inputs)\n","        output = self.linear_output(features)\n","\n","        return output\n","\n","    def get_features(self, head_inputs: dict):\n","\n","        last_hidden_state = head_inputs['output_model'][0]\n","        attention_mask = head_inputs['attention_mask']\n","\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","\n","        return mean_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T10:17:45.503282Z","iopub.status.busy":"2023-08-29T10:17:45.502611Z","iopub.status.idle":"2023-08-29T10:17:45.519139Z","shell.execute_reply":"2023-08-29T10:17:45.518334Z","shell.execute_reply.started":"2023-08-29T10:17:45.503251Z"},"id":"NmvJZiQ9PaKc","trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, model_path: str, layers_freeze: int):\n","        super().__init__()\n","\n","        self.config_model = AutoConfig.from_pretrained(model_path)\n","        self.config_model.attention_probs_dropout_prob = 0\n","        self.config_model.hidden_dropout_prob = 0\n","\n","        self.model = AutoModel.from_pretrained(model_path, config=self.config_model)\n","        self.hidden_size = self.config_model.hidden_size\n","        self.num_hidden_layers = self.config_model.num_hidden_layers\n","\n","        if layers_freeze > 0:\n","            if layers_freeze == self.num_hidden_layers:\n","                print(f'Freezing all model')\n","                self.model.requires_grad_(False)\n","            else:\n","                print(f'Freezing the first {layers_freeze} layers')\n","                self.freeze_layers(layers_freeze)\n","\n","        self.head = MeanHead(self.hidden_size, self.num_hidden_layers)\n","\n","    def freeze_layers(self, layers: int):\n","\n","        self.model.embeddings.requires_grad_(False)\n","        self.model.encoder.layer[:layers].requires_grad_(False)\n","\n","    def take_features(self, inputs):\n","        output_model = self.model(**inputs, return_dict=False, output_hidden_states = False)\n","\n","        inputs['output_model'] = output_model\n","\n","        return inputs\n","\n","    def forward(self, inputs):\n","\n","        features = self.take_features(inputs)\n","\n","        return self.head(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbJhbbTpA2Ao"},"outputs":[],"source":["def tokenize_samples(samples, CFG):\n","\n","  tokenized = CFG['TOKENIZER'](\n","            samples,\n","            add_special_tokens=True,\n","            max_length=CFG['MAX_LEN'],\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            verbose=False\n","        )\n","\n","  inputs = {'input_ids': torch.tensor(tokenized['input_ids'], dtype=torch.long),\n","                  'attention_mask': torch.tensor(tokenized['attention_mask'], dtype=torch.long)}\n","\n","  return inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"884wtbks_JgM"},"outputs":[],"source":["def inference(samples, model, CFG):\n","\n","  inputs = tokenize_samples(samples, CFG)\n","\n","  inputs = {k:inputs[k].to(device=CFG['DEVICE']) for k in inputs.keys()}\n","\n","  model.eval()\n","  with torch.no_grad():\n","    with autocast(device_type=CFG['DEVICE'], dtype=torch.float16):\n","      output = model(inputs)\n","\n","  preds = torch.argmax(F.softmax(output, 1), 1).cpu().detach().numpy()\n","\n","  return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jHyEpIhZ-bpN"},"outputs":[],"source":["model_path = '/content/drive/MyDrive/PLN - Projeto/DebertaV3'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GAjIX3Cf-bGe"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzbR5SumdLFS"},"outputs":[],"source":["Configs = {\n","    'MAX_LEN':  256,\n","    'MODEL_PATH': '/content/drive/MyDrive/PLN - Projeto/DebertaV3',\n","    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',\n","    'TOKENIZER': tokenizer\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15968,"status":"ok","timestamp":1699556606616,"user":{"displayName":"Adriel dos Santos Araujo Cabral","userId":"01219458395452816246"},"user_tz":180},"id":"QYtg_RVu5e0x","outputId":"e5e2724e-e351-4bf5-b20f-f9dabc46dfa2"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model = CustomModel(Configs['MODEL_PATH'], 0)\n","model.to(Configs['DEVICE'])\n","\n","model.load_state_dict(torch.load('/content/drive/MyDrive/PLN - Projeto/deberta_best.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJyPeFmzopYG"},"outputs":[],"source":["samples = [\n","            'exemplo'\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LATnLBacollo"},"outputs":[],"source":["inference(samples, model, Configs)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
