{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31054,"status":"ok","timestamp":1699556966528,"user":{"displayName":"Adriel dos Santos Araujo Cabral","userId":"01219458395452816246"},"user_tz":180},"id":"S0eGbTaHJwHJ","outputId":"fa154324-302a-4a12-f5df-7dc4b7d0f652"},"outputs":[],"source":["!pip install --no-cache-dir transformers sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T12:19:37.846866Z","iopub.status.busy":"2023-11-04T12:19:37.846447Z","iopub.status.idle":"2023-11-04T12:19:52.307192Z","shell.execute_reply":"2023-11-04T12:19:52.305975Z","shell.execute_reply.started":"2023-11-04T12:19:37.846830Z"},"id":"f53351de","papermill":{"duration":9.64213,"end_time":"2022-10-18T01:53:17.259565","exception":false,"start_time":"2022-10-18T01:53:07.617435","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import random\n","import math\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n","\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import AdamW\n","from torch.cuda.amp import GradScaler\n","from torch import autocast\n","\n","import transformers\n","from transformers import TrainingArguments, Trainer\n","from transformers import AutoTokenizer, AutoConfig, AutoModel\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"doinHjIBJp7c"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-04T12:19:52.311581Z","iopub.status.busy":"2023-11-04T12:19:52.310467Z","iopub.status.idle":"2023-11-04T12:19:52.326945Z","shell.execute_reply":"2023-11-04T12:19:52.326083Z","shell.execute_reply.started":"2023-11-04T12:19:52.311538Z"},"id":"ogZ8R7bUPaKX","trusted":true},"outputs":[],"source":["def seed_everything(seed: int):\n","\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed_everything(0)\n","\n","g = torch.Generator()\n","g.manual_seed(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T10:17:45.447834Z","iopub.status.busy":"2023-08-29T10:17:45.447289Z","iopub.status.idle":"2023-08-29T10:17:45.459399Z","shell.execute_reply":"2023-08-29T10:17:45.458521Z","shell.execute_reply.started":"2023-08-29T10:17:45.447802Z"},"id":"DPJMS_myPaKZ","trusted":true},"outputs":[],"source":["class MeanHead(nn.Module):\n","    def __init__(self, hidden_size: int, num_hidden_layers: int):\n","        super(MeanHead, self).__init__()\n","\n","        self.linear_output = nn.Sequential(\n","                                nn.Dropout(p = 0.2),\n","                                nn.Linear(hidden_size, 3)\n","                              )\n","\n","    def forward(self, head_inputs: dict):\n","\n","        features = self.get_features(head_inputs)\n","        output = self.linear_output(features)\n","\n","        return output\n","\n","    def get_features(self, head_inputs: dict):\n","\n","        last_hidden_state = head_inputs['output_model'][0]\n","        attention_mask = head_inputs['attention_mask']\n","\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","\n","        return mean_embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T10:17:45.503282Z","iopub.status.busy":"2023-08-29T10:17:45.502611Z","iopub.status.idle":"2023-08-29T10:17:45.519139Z","shell.execute_reply":"2023-08-29T10:17:45.518334Z","shell.execute_reply.started":"2023-08-29T10:17:45.503251Z"},"id":"NmvJZiQ9PaKc","trusted":true},"outputs":[],"source":["class CustomModel(nn.Module):\n","    def __init__(self, model_path: str, layers_freeze: int):\n","        super().__init__()\n","\n","        self.config_model = AutoConfig.from_pretrained(model_path)\n","        self.config_model.attention_probs_dropout_prob = 0\n","        self.config_model.hidden_dropout_prob = 0\n","\n","        self.model = AutoModel.from_pretrained(model_path, config=self.config_model)\n","        self.hidden_size = self.config_model.hidden_size\n","        self.num_hidden_layers = self.config_model.num_hidden_layers\n","\n","        if layers_freeze > 0:\n","            if layers_freeze == self.num_hidden_layers:\n","                print(f'Freezing all model')\n","                self.model.requires_grad_(False)\n","            else:\n","                print(f'Freezing the first {layers_freeze} layers')\n","                self.freeze_layers(layers_freeze)\n","\n","        self.head = MeanHead(self.hidden_size, self.num_hidden_layers)\n","\n","    def freeze_layers(self, layers: int):\n","\n","        self.model.embeddings.requires_grad_(False)\n","        self.model.encoder.layer[:layers].requires_grad_(False)\n","\n","    def take_features(self, inputs):\n","        output_model = self.model(**inputs, return_dict=False, output_hidden_states = False)\n","\n","        inputs['output_model'] = output_model\n","\n","        return inputs\n","\n","    def forward(self, inputs):\n","\n","        features = self.take_features(inputs)\n","\n","        return self.head(features)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T10:17:45.525116Z","iopub.status.busy":"2023-08-29T10:17:45.524462Z","iopub.status.idle":"2023-08-29T10:17:45.536145Z","shell.execute_reply":"2023-08-29T10:17:45.535243Z","shell.execute_reply.started":"2023-08-29T10:17:45.525092Z"},"id":"c_0ihtKBPaKc","trusted":true},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, df, tokenizer, max_len):\n","\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        text = self.df['discurso'][idx]\n","\n","        tokenized = self.tokenizer(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            verbose=False\n","        )\n","\n","        labels = self.df['label'][idx]\n","        targets = torch.tensor(labels, dtype=torch.long)\n","\n","\n","        token_output = {'input_ids': torch.tensor(tokenized['input_ids'], dtype=torch.long),\n","                        'attention_mask': torch.tensor(tokenized['attention_mask'], dtype=torch.long)}\n","\n","        return token_output, targets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T10:17:46.842425Z","iopub.status.busy":"2023-08-29T10:17:46.841547Z","iopub.status.idle":"2023-08-29T10:17:46.848222Z","shell.execute_reply":"2023-08-29T10:17:46.84719Z","shell.execute_reply.started":"2023-08-29T10:17:46.842385Z"},"id":"-KMKiN45PaKd","trusted":true},"outputs":[],"source":["def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T10:17:46.850258Z","iopub.status.busy":"2023-08-29T10:17:46.849807Z","iopub.status.idle":"2023-08-29T10:17:46.859644Z","shell.execute_reply":"2023-08-29T10:17:46.8586Z","shell.execute_reply.started":"2023-08-29T10:17:46.850224Z"},"id":"fKSlytnuPaKd","trusted":true},"outputs":[],"source":["def get_loaders(CFG):\n","\n","    train = CustomDataset(CFG['TRAIN_DF'], CFG['TOKENIZER'], CFG['MAX_LEN'])\n","\n","    train_loader = torch.utils.data.DataLoader(train,\n","                             shuffle=True,\n","                             pin_memory=True,\n","                             batch_size=CFG['BATCH_SIZE'],\n","                             num_workers=0,\n","                            worker_init_fn=seed_worker,\n","                            generator=g)\n","\n","    valid = CustomDataset(CFG['VAL_DF'], CFG['TOKENIZER'], CFG['MAX_LEN'])\n","\n","    valid_loader = torch.utils.data.DataLoader(valid,\n","                             shuffle=False,\n","                             pin_memory=True,\n","                             batch_size=CFG['BATCH_SIZE'] * 6,\n","                             num_workers=0,\n","                            worker_init_fn=seed_worker,\n","                            generator=g)\n","\n","    return train_loader, valid_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T10:17:46.916343Z","iopub.status.busy":"2023-08-29T10:17:46.915944Z","iopub.status.idle":"2023-08-29T10:17:46.927718Z","shell.execute_reply":"2023-08-29T10:17:46.926786Z","shell.execute_reply.started":"2023-08-29T10:17:46.916311Z"},"id":"3r-WN0dTPaKd","trusted":true},"outputs":[],"source":["from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-29T10:17:46.930292Z","iopub.status.busy":"2023-08-29T10:17:46.929811Z","iopub.status.idle":"2023-08-29T10:17:46.946616Z","shell.execute_reply":"2023-08-29T10:17:46.945576Z","shell.execute_reply.started":"2023-08-29T10:17:46.930254Z"},"id":"mfYfy8g_PaKd","trusted":true},"outputs":[],"source":["class CustomScheduler:\n","    def __init__(self, optimizer, total_steps, warmup_steps=0):\n","        self.warmup_steps = int(warmup_steps)\n","        self.optimizer = optimizer\n","        self.lr_warmup = {}\n","        self.linear_decay_layers = {}\n","\n","        steps_decay_linear_lr = total_steps - self.warmup_steps\n","        for index, _ in enumerate(self.optimizer.param_groups):\n","            lr_linear_decay = self.optimizer.param_groups[index][\"lr\"] / steps_decay_linear_lr\n","            self.linear_decay_layers[f\"{index}\"] = lr_linear_decay\n","\n","        self.initial_lr = {}\n","        for index, _ in enumerate(self.optimizer.param_groups):\n","            self.initial_lr[f\"{index}\"] = self.optimizer.param_groups[index][\"lr\"]\n","\n","        if (self.warmup_steps):\n","            for index, _ in enumerate(self.optimizer.param_groups):\n","                lr_step_warmup = (self.optimizer.param_groups[index][\"lr\"] - self.optimizer.param_groups[index][\"min_lr\"]) / self.warmup_steps\n","                self.lr_warmup[f\"{index}\"] = lr_step_warmup\n","                self.optimizer.param_groups[index][\"lr\"] = self.optimizer.param_groups[index][\"min_lr\"]\n","\n","    def step(self, current_step):\n","\n","        if self.warmup_steps > current_step:\n","            for index, _ in enumerate(self.optimizer.param_groups):\n","                self.optimizer.param_groups[index][\"lr\"] += self.lr_warmup[f\"{index}\"]\n","        else:\n","            for index, _ in enumerate(self.optimizer.param_groups):\n","                self.optimizer.param_groups[index][\"lr\"]  -= self.linear_decay_layers[f\"{index}\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cfEhJp4dKw9x"},"outputs":[],"source":["all_data = pd.read_csv('/content/drive/MyDrive/PLN - Projeto/data_label.csv').drop(columns=['Unnamed: 0'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YcL2qRMKK6fB"},"outputs":[],"source":["lb_encoder = LabelEncoder()\n","all_data['label'] = lb_encoder.fit_transform(all_data['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Nvr-1RGLDjT"},"outputs":[],"source":["all_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n_13aR6JLCZp"},"outputs":[],"source":["train_val_df, test_df = train_test_split(all_data, test_size=0.1, random_state=42, stratify=all_data.label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-KLalt9L8kz"},"outputs":[],"source":["train_df, val_df = train_test_split(train_val_df, test_size=0.2, random_state=42, stratify=train_val_df.label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JqBRcdgrSStI"},"outputs":[],"source":["train_df = train_df.reset_index(drop=True)\n","val_df = val_df.reset_index(drop=True)\n","test_df = test_df.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i_YFD1rijst0"},"outputs":[],"source":["def get_optimizer_grouped_parameters(model, CFG):\n","\n","    groups = [['layer.0.','layer.1.','layer.2.'],\n","             ['layer.3.', 'layer.4.','layer.5.'],\n","             ['layer.6.','layer.7.', 'layer.8.'],\n","             ['layer.9.','layer.10.','layer.11.']]\n","\n","    all_groups =['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.']\n","\n","\n","    optimizer_grouped_parameters = [\n","         {'params': [p for i, (n, p) in enumerate(model.named_parameters()) if not any(nd in n for nd in all_groups) and i < 5],'weight_decay': CFG['WGD'], 'lr': CFG['LR']*0.89, 'min_lr': 0},\n","         {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in groups[0])],'weight_decay': CFG['WGD'], 'lr': CFG['LR']*0.91, 'min_lr': 0},\n","         {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in groups[1])],'weight_decay': CFG['WGD'], 'lr': CFG['LR']*0.93, 'min_lr': 0},\n","         {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in groups[2])],'weight_decay': CFG['WGD'], 'lr': CFG['LR']*0.95, 'min_lr': 0},\n","         {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in groups[3])],'weight_decay': CFG['WGD'], 'lr': CFG['LR']*0.97, 'min_lr': 0},\n","         {'params': [p for i, (n, p) in enumerate(model.named_parameters()) if not any(nd in n for nd in all_groups) and i > 10 ],'weight_decay': CFG['WGD'], 'lr': CFG['LR'], 'min_lr': 0}\n","    ]\n","\n","    return optimizer_grouped_parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbJhbbTpA2Ao"},"outputs":[],"source":["def tokenize_samples(samples, CFG):\n","\n","  tokenized = CFG['TOKENIZER'](\n","            samples,\n","            add_special_tokens=True,\n","            max_length=CFG['MAX_LEN'],\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            verbose=False\n","        )\n","\n","  inputs = {'input_ids': torch.tensor(tokenized['input_ids'], dtype=torch.long),\n","                  'attention_mask': torch.tensor(tokenized['attention_mask'], dtype=torch.long)}\n","\n","  return inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"884wtbks_JgM"},"outputs":[],"source":["def inference(samples, model, CFG):\n","\n","  inputs = tokenize_samples(samples, CFG)\n","\n","  inputs = {k:inputs[k].to(device=CFG['DEVICE']) for k in inputs.keys()}\n","\n","  model.eval()\n","  with torch.no_grad():\n","    output = model(inputs)\n","\n","  preds = torch.argmax(F.softmax(output, 1), 1).cpu().detach().numpy()\n","\n","  return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7ccOVcuu3xR"},"outputs":[],"source":["def train_epoch(model, loader, optimizer, loss_func, schedule, global_steps, scaler, CFG):\n","\n","  avg_train_loss = 0\n","\n","  train_preds = []\n","  train_targets = []\n","\n","  model.train()\n","  for inputs, targets in tqdm(loader, total=len(loader)):\n","\n","      inputs = {k:inputs[k].to(device=CFG['DEVICE']) for k in inputs.keys()}\n","      targets = targets.to(device=CFG['DEVICE'])\n","\n","      with autocast(device_type=CFG['DEVICE'], dtype=torch.float16):\n","        output = model(inputs)\n","        loss = loss_func(output, targets)\n","\n","      optimizer.zero_grad()\n","\n","      scaler.scale(loss).backward()\n","\n","      #scaler.unscale_(optimizer)\n","      #torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","\n","      scaler.step(optimizer)\n","      scaler.update()\n","\n","      schedule.step(global_steps)\n","\n","      avg_train_loss += loss.item()\n","      train_preds.append(torch.argmax(F.softmax(output, 1), 1).cpu().detach().numpy())\n","      train_targets.append(targets.cpu().detach().numpy())\n","      global_steps += 1\n","\n","      del inputs, targets, output, loss\n","\n","  torch.cuda.empty_cache()\n","\n","  print(f'AVG TRAIN LOSS: {avg_train_loss / len(loader)} / TRAIN accuracy: {accuracy_score(np.concatenate(train_targets).reshape(-1), np.concatenate(train_preds).reshape(-1))}')\n","\n","  return global_steps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8kXBqVmcw54A"},"outputs":[],"source":["def validation_epoch(model, loader, loss_func, best_score, CFG):\n","\n","  avg_valid_loss = 0\n","\n","  val_preds = []\n","  val_targets = []\n","\n","  model.eval()\n","  with torch.no_grad():\n","      for inputs, targets in tqdm(loader, total=len(loader)):\n","          inputs = {k:inputs[k].to(device=CFG['DEVICE']) for k in inputs.keys()}\n","          targets = targets.to(device=CFG['DEVICE'])\n","\n","          with autocast(device_type=CFG['DEVICE'], dtype=torch.float16):\n","            output = model(inputs)\n","            loss = loss_func(output, targets)\n","\n","          avg_valid_loss += loss.item()\n","          val_preds.append(torch.argmax(F.softmax(output, 1), 1).cpu().detach().numpy())\n","          val_targets.append(targets.cpu().detach().numpy())\n","\n","          del inputs, targets, output, loss\n","\n","  torch.cuda.empty_cache()\n","\n","  val_preds = np.concatenate(val_preds).reshape(-1)\n","  val_targets = np.concatenate(val_targets).reshape(-1)\n","\n","  valid_accuracy = accuracy_score(val_targets, val_preds)\n","\n","  print(f'AVG VALID LOSS: {avg_valid_loss / len(loader)} / VALID accuracy: {valid_accuracy}')\n","\n","  if valid_accuracy > best_score:\n","      best_score = valid_accuracy\n","      print(f\"{'-'*20} Saving model, Score: {best_score} {'-'*20}\")\n","      torch.save(model.state_dict(), f'/content/drive/MyDrive/PLN - Projeto/deberta_best.pth')\n","\n","  return val_preds, val_targets, best_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qVrnboyozAl4"},"outputs":[],"source":["def train_model(CFG):\n","  train_loader, valid_loader = get_loaders(CFG)\n","\n","  model = CustomModel(CFG['MODEL_PATH'], CFG['FREEZE_LAYERS'])\n","\n","  #print(model)\n","\n","  # for i, (n, p) in enumerate(model.named_parameters()):\n","  #   print(n)\n","\n","  loss_func = nn.CrossEntropyLoss(reduction='mean')\n","\n","  #parameters = [\n","  #         {'params': [p for p in model.parameters()],'weight_decay': CFG['WGD'], 'lr': CFG['LR'], 'min_lr': CFG['MIN_LR']}]\n","\n","  optimizer_grouped_parameters = get_optimizer_grouped_parameters(model, CFG)\n","\n","  optimizer = AdamW(optimizer_grouped_parameters, lr=CFG['LR'])\n","\n","  custom_lr_scheduler = CustomScheduler(optimizer,\n","                                        int(CFG['EPOCHS'] * len(train_loader)),\n","                                        int(CFG['EPOCHS'] * len(train_loader) * CFG['WARMUP_PERCENT'])\n","                                       )\n","\n","  global_steps = 0\n","  best_score = 0\n","\n","  model.to(CFG['DEVICE'])\n","\n","  scaler = GradScaler()\n","\n","  for epoch in tqdm(range(0, CFG['EPOCHS']), desc=\"Training...\"):\n","    print(f\"{'-'*30} EPOCH {epoch + 1} / {CFG['EPOCHS']} {'-'*30}\")\n","\n","    global_steps = train_epoch(model, train_loader, optimizer, loss_func, custom_lr_scheduler, global_steps, scaler, CFG)\n","    _, _, best_score = validation_epoch(model, valid_loader, loss_func, best_score, CFG)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jHyEpIhZ-bpN"},"outputs":[],"source":["model_path = '/content/drive/MyDrive/PLN - Projeto/DebertaV3'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GAjIX3Cf-bGe"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzbR5SumdLFS"},"outputs":[],"source":["Configs = {\n","    'TRAIN_DF': train_df,\n","    'VAL_DF': val_df,\n","    'LR': 1e-5,\n","    'MIN_LR': 0,\n","    'WGD': 0.01,\n","    'MAX_LEN':  256,\n","    'MODEL_PATH': '/content/drive/MyDrive/PLN - Projeto/DebertaV3',\n","    'EPOCHS': 5,\n","    'BATCH_SIZE': 20,\n","    'DEVICE': 'cuda' if torch.cuda.is_available() else 'cpu',\n","    'FREEZE_LAYERS': 0,\n","    'WARMUP_PERCENT': 0.12,\n","    'TOKENIZER': tokenizer\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Suj9aYam3sVO"},"outputs":[],"source":["train_model(Configs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rDThqAJU4Umi"},"outputs":[],"source":["train_loader, valid_loader = get_loaders(Configs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QYtg_RVu5e0x"},"outputs":[],"source":["model = CustomModel(Configs['MODEL_PATH'], Configs['FREEZE_LAYERS'])\n","model.to(Configs['DEVICE'])\n","\n","model.load_state_dict(torch.load('/content/drive/MyDrive/PLN - Projeto/deberta_best.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zDijJDaE6oaQ"},"outputs":[],"source":["loss_func = nn.CrossEntropyLoss(reduction='mean')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OzQ4T4wn5eHi"},"outputs":[],"source":["preds, targets, _ = validation_epoch(model, valid_loader, loss_func, 1.0, Configs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lAYNWZie3uXC"},"outputs":[],"source":["cm = confusion_matrix(targets, preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8lq0Vnn06SKy"},"outputs":[],"source":["disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n","                             display_labels=lb_encoder.classes_)\n","\n","disp.plot()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"21csRUL16S1Q"},"outputs":[],"source":["test = CustomDataset(test_df, Configs['TOKENIZER'], Configs['MAX_LEN'])\n","\n","test_loader = torch.utils.data.DataLoader(test,\n","                            pin_memory=True,\n","                            batch_size=Configs['BATCH_SIZE'] * 6,\n","                            num_workers=0,\n","                            worker_init_fn=seed_worker,\n","                            generator=g)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waGwUV1O6jpR"},"outputs":[],"source":["preds, targets, _ = validation_epoch(model, test_loader, loss_func, 1.0, Configs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcckXpna6z2i"},"outputs":[],"source":["cm = confusion_matrix(targets, preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mz--8EMG62mY"},"outputs":[],"source":["disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n","                             display_labels=lb_encoder.classes_)\n","\n","disp.plot()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nYdyYOdN9rNR"},"outputs":[],"source":["preds, targets, _ = validation_epoch(model, train_loader, loss_func, 1.0, Configs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XsoZMywa9u33"},"outputs":[],"source":["cm = confusion_matrix(targets, preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hm7l1OFZ9vMR"},"outputs":[],"source":["disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n","                             display_labels=lb_encoder.classes_)\n","\n","disp.plot()\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
